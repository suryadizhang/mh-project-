# ğŸ—ï¸ Backend Architecture Explained

**Date**: November 4, 2025

---

## ğŸ“Š Current Architecture: 3 Main.py Files

### **File 1: `/src/main.py` (37 KB) - PRIMARY UNIFIED SERVER** âœ…

**Purpose**: Single unified FastAPI application serving EVERYTHING  
**Runs on**: Port 8000 via `run_backend.py`  
**Status**: âœ… **ACTIVE - This is what's running**

**What it includes:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         src/main.py (PRIMARY SERVER)                â”‚
â”‚                                                     â”‚
â”‚  ğŸ“¦ Core System (Database & Business Logic)        â”‚
â”‚     â€¢ Bookings, Customers, Payments                â”‚
â”‚     â€¢ Leads, Newsletter, Reviews                   â”‚
â”‚     â€¢ Stripe integration                           â”‚
â”‚     â€¢ Email & SMS services                         â”‚
â”‚     â€¢ Admin panels & Analytics                     â”‚
â”‚                                                     â”‚
â”‚  ğŸ¤– AI System (Embedded)                           â”‚
â”‚     â€¢ AI Chat endpoints (/api/v1/ai/*)             â”‚
â”‚     â€¢ AI Orchestrator                              â”‚
â”‚     â€¢ Multi-channel AI (email, SMS, Instagram)     â”‚
â”‚     â€¢ Intent routing & emotion detection           â”‚
â”‚     â€¢ Self-learning AI                             â”‚
â”‚                                                     â”‚
â”‚  ğŸ”§ Enterprise Features                            â”‚
â”‚     â€¢ Sentry monitoring                            â”‚
â”‚     â€¢ Prometheus metrics (/metrics)                â”‚
â”‚     â€¢ CQRS + Event Sourcing                        â”‚
â”‚     â€¢ Outbox workers (background jobs)             â”‚
â”‚     â€¢ Multi-layer rate limiting                    â”‚
â”‚     â€¢ K8s health checks (/ready, /info)            â”‚
â”‚     â€¢ Station Management (Multi-tenant RBAC)       â”‚
â”‚                                                     â”‚
â”‚  ğŸŒ All Routers (30+)                              â”‚
â”‚     /api/auth, /api/bookings, /api/stripe          â”‚
â”‚     /api/leads, /api/reviews, /api/crm             â”‚
â”‚     /api/v1/ai/*, /api/admin/*                     â”‚
â”‚     /api/station/*, /api/qr/*                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**How it works:**

```bash
# Start command
python run_backend.py

# run_backend.py executes:
uvicorn.run("main:app", port=8000)
         â†“
# Loads src/main.py which includes EVERYTHING
```

---

### **File 2: `/src/api/ai/endpoints/main.py` (4.8 KB) - AI MICROSERVICE** âš ï¸

**Purpose**: Standalone AI-only FastAPI app (if you want to run AI
separately)  
**Runs on**: Port 8002 (if started manually)  
**Status**: âš ï¸ **NOT CURRENTLY RUNNING** (AI is embedded in primary
main.py)

**What it includes:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    api/ai/endpoints/main.py (AI STANDALONE)         â”‚
â”‚                                                     â”‚
â”‚  ğŸ¤– AI-Only Endpoints                              â”‚
â”‚     â€¢ /api/chat/* - Chat endpoints                 â”‚
â”‚     â€¢ /api/admin/* - AI admin                      â”‚
â”‚     â€¢ /webhooks/* - AI webhooks                    â”‚
â”‚     â€¢ WebSocket support                            â”‚
â”‚                                                     â”‚
â”‚  ğŸ“Š Minimal Setup                                  â”‚
â”‚     â€¢ Basic health check                           â”‚
â”‚     â€¢ OpenAI configuration                         â”‚
â”‚     â€¢ No database (relies on external DB)          â”‚
â”‚     â€¢ No business logic                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**When to use:**

- If you want to run AI as a separate microservice
- For horizontal scaling (AI service on different servers)
- For testing AI features in isolation

**To start separately:**

```bash
cd apps/backend/src/api/ai/endpoints
python main.py  # Runs on port 8002
```

---

### **File 3: `/src/api/app/main.py` (20 KB) - LEGACY** âŒ

**Purpose**: Old main.py from before consolidation  
**Status**: âŒ **DEPRECATED - Should be deleted**

**What it had:**

- Sentry, Prometheus, CQRS, Workers (now merged into primary)
- Station management (now merged into primary)
- Old router structure (now merged into primary)

**Why it exists:**

- Historical artifact from before Phase 1 consolidation
- Some tests still import from it (need to fix)
- Will be deleted after Phase 2 complete

---

## ğŸ¯ Answer to Your Question

### **Do Database and AI use the same main.py?**

**YES! Currently: UNIFIED ARCHITECTURE** âœ…

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                      â”‚
â”‚               src/main.py (ONE SERVER)               â”‚
â”‚               Running on Port 8000                   â”‚
â”‚                                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚  Database Systemâ”‚      â”‚    AI System     â”‚     â”‚
â”‚  â”‚                 â”‚      â”‚                  â”‚     â”‚
â”‚  â”‚ â€¢ PostgreSQL    â”‚      â”‚ â€¢ OpenAI API     â”‚     â”‚
â”‚  â”‚ â€¢ Redis cache   â”‚      â”‚ â€¢ Chat service   â”‚     â”‚
â”‚  â”‚ â€¢ SQLAlchemy    â”‚      â”‚ â€¢ Intent router  â”‚     â”‚
â”‚  â”‚ â€¢ Alembic       â”‚      â”‚ â€¢ Orchestrator   â”‚     â”‚
â”‚  â”‚                 â”‚      â”‚ â€¢ Self-learning  â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚           â”‚                        â”‚               â”‚
â”‚           â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â”‚
â”‚                    â”‚                               â”‚
â”‚           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                    â”‚
â”‚           â”‚  Shared Resources â”‚                    â”‚
â”‚           â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤                    â”‚
â”‚           â”‚ â€¢ Auth/JWT        â”‚                    â”‚
â”‚           â”‚ â€¢ Rate limiting   â”‚                    â”‚
â”‚           â”‚ â€¢ Logging         â”‚                    â”‚
â”‚           â”‚ â€¢ Monitoring      â”‚                    â”‚
â”‚           â”‚ â€¢ Middleware      â”‚                    â”‚
â”‚           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                    â”‚
â”‚                                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

         â†“
    All requests to: http://localhost:8000
         â†“
    â€¢ Business endpoints: /api/bookings, /api/leads
    â€¢ AI endpoints: /api/v1/ai/chat
    â€¢ Admin endpoints: /api/admin/*
```

---

## ğŸ”„ Architecture Options

### **Option 1: UNIFIED (Current)** âœ…

```
Single Server: src/main.py
â”œâ”€â”€ Database operations
â”œâ”€â”€ Business logic
â”œâ”€â”€ AI features
â””â”€â”€ All routers

Pros:
âœ… Simple deployment (one service)
âœ… Shared auth, logging, monitoring
âœ… No network latency between components
âœ… Easier development & debugging

Cons:
âŒ Can't scale AI independently
âŒ Larger memory footprint
âŒ Single point of failure
```

### **Option 2: MICROSERVICES (Available but not active)**

```
Server 1: src/main.py (Port 8000)
â”œâ”€â”€ Database operations
â”œâ”€â”€ Business logic
â””â”€â”€ Core routers

Server 2: api/ai/endpoints/main.py (Port 8002)
â”œâ”€â”€ AI chat
â”œâ”€â”€ AI orchestrator
â””â”€â”€ AI-only endpoints

Pros:
âœ… Independent scaling (AI needs more resources)
âœ… Isolated failures (AI down â‰  business down)
âœ… Different deployment schedules

Cons:
âŒ More complex deployment
âŒ Need service-to-service auth
âŒ Network latency between services
âŒ Duplicate middleware/monitoring
```

---

## ğŸ“ File Structure Mapping

```
apps/backend/
â”‚
â”œâ”€â”€ run_backend.py              # Starts primary server
â”‚
â””â”€â”€ src/
    â”‚
    â”œâ”€â”€ main.py                 # âœ… PRIMARY (37 KB)
    â”‚                           # Runs everything (DB + AI + Enterprise)
    â”‚                           # Port 8000
    â”‚
    â”œâ”€â”€ core/                   # Shared by main.py
    â”‚   â”œâ”€â”€ database.py         # PostgreSQL + SQLAlchemy
    â”‚   â”œâ”€â”€ config.py           # Settings
    â”‚   â”œâ”€â”€ auth.py             # JWT authentication
    â”‚   â””â”€â”€ rate_limiting.py    # Rate limiter
    â”‚
    â”œâ”€â”€ services/               # Business services (used by main.py)
    â”‚   â”œâ”€â”€ booking_service.py
    â”‚   â”œâ”€â”€ email_service.py
    â”‚   â”œâ”€â”€ lead_service.py
    â”‚   â””â”€â”€ ...
    â”‚
    â”œâ”€â”€ api/
    â”‚   â”‚
    â”‚   â”œâ”€â”€ ai/
    â”‚   â”‚   â”œâ”€â”€ routers/        # AI routers (imported by main.py)
    â”‚   â”‚   â”œâ”€â”€ services/       # AI services (imported by main.py)
    â”‚   â”‚   â””â”€â”€ endpoints/
    â”‚   â”‚       â””â”€â”€ main.py     # âš ï¸ STANDALONE AI (4.8 KB)
    â”‚   â”‚                       # Optional separate AI server
    â”‚   â”‚                       # Port 8002 (if started)
    â”‚   â”‚
    â”‚   â””â”€â”€ app/
    â”‚       â”œâ”€â”€ routers/        # Business routers (imported by main.py)
    â”‚       â”œâ”€â”€ services/       # âš ï¸ DUPLICATES (to be deleted)
    â”‚       â””â”€â”€ main.py         # âŒ LEGACY (20 KB)
    â”‚                           # Old server (to be deleted)
    â”‚
    â””â”€â”€ models/                 # Database models (used by main.py)
        â”œâ”€â”€ booking.py
        â”œâ”€â”€ user.py
        â””â”€â”€ ...
```

---

## ğŸš€ Current Runtime

```
Terminal: powershell (separate window)
Command: python run_backend.py

â†“

Process: uvicorn running "main:app"
PID: [varies]
Port: 8000
Memory: ~300 MB (includes AI models)

â†“

What's loaded in memory:
âœ… PostgreSQL connection pool
âœ… Redis connection (rate limiting, cache)
âœ… OpenAI client (AI features)
âœ… All 30+ routers
âœ… DI container with repositories
âœ… AI Orchestrator with scheduler
âœ… Outbox workers (background jobs)
âœ… Sentry monitoring
âœ… Prometheus metrics collector
```

---

## ğŸ¯ Recommendation

**Keep the UNIFIED architecture (current setup)** âœ…

**Reasons:**

1. **Simpler**: One deployment, one service, one config
2. **Faster**: No network calls between DB and AI
3. **Cheaper**: One server vs two servers
4. **Easier debugging**: All logs in one place
5. **Better for small/medium scale**: You're not at Netflix scale yet

**When to switch to microservices:**

- AI queries take too long and slow down bookings
- Need to scale AI independently (add more AI servers)
- AI crashes and takes down the whole system
- Team grows and different teams own different services

**Current scale**: UNIFIED is perfect âœ…

---

## ğŸ” What Should We Do?

### **Phase 2 Plan:**

1. âœ… **Keep**: `src/main.py` (primary unified server)
2. âœ… **Keep**: `api/ai/endpoints/main.py` (option for future
   microservice)
3. âŒ **Delete**: `api/app/main.py` (legacy, now redundant)
4. ğŸ”„ **Cleanup**: Remove duplicate services in `api/app/services/`
5. ğŸ”„ **Update imports**: Point all imports to canonical locations

**Result**: Clean unified architecture with option to split later if
needed.

---

## ğŸ’¡ Summary

**Question**: Do database and AI use the same main.py?

**Answer**: **YES!** They both use `src/main.py` (37 KB)

**Why**:

- Simpler architecture
- Better performance (no network latency)
- Easier to maintain
- Shared authentication & monitoring

**The AI-only main.py exists** (`api/ai/endpoints/main.py`) but is
**NOT running**. It's there as an option if you want to split into
microservices later.

**Current setup**:

```
ONE SERVER = Database + AI + Everything
Port 8000 = All your APIs (business + AI)
```

This is the RIGHT architecture for your current scale! âœ…
