name: ğŸ›¡ï¸ Repository Guard & Quality Gate

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main, develop ]

env:
  PYTHON_VERSION: '3.11'

jobs:
  # Job 1: Repository Guard - Security & Quality Enforcement
  repository-guard:
    name: ğŸ›¡ï¸ Repository Guard
    runs-on: ubuntu-latest
    outputs:
      violations_found: ${{ steps.guard-check.outputs.violations_found }}
      critical_violations: ${{ steps.guard-check.outputs.critical_violations }}
    
    steps:
    - name: ğŸ“¥ Checkout Repository
      uses: actions/checkout@v4
      with:
        fetch-depth: 0  # Full history for comprehensive scanning
    
    - name: ğŸ Setup Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        cache: 'pip'
    
    - name: ğŸ“¦ Install Guard Dependencies
      run: |
        pip install colorama
    
    - name: ğŸ›¡ï¸ Run Repository Guard
      id: guard-check
      run: |
        echo "::group::Repository Guard Scan"
        python guard.py --json-output guard-report.json
        echo "::endgroup::"
        
        # Parse results for GitHub Actions
        violations=$(python -c "
        import json
        with open('guard-report.json') as f:
            data = json.load(f)
        
        total = len(data['violations'])
        critical = sum(1 for v in data['violations'] 
                      if v['type'] in ['HARDCODED_SECRET', 'CROSS_IMPORT_VIOLATION'])
        
        print(f'violations_found={total}')
        print(f'critical_violations={critical}')
        ")
        
        echo "$violations" >> $GITHUB_OUTPUT
        
        # Fail on critical violations
        critical_count=$(echo "$violations" | grep "critical_violations=" | cut -d'=' -f2)
        if [ "$critical_count" -gt 0 ]; then
          echo "âŒ Critical violations found! Failing build."
          exit 1
        fi
      continue-on-error: true
    
    - name: ğŸ“Š Upload Guard Report
      uses: actions/upload-artifact@v3
      if: always()
      with:
        name: guard-report
        path: guard-report.json
        retention-days: 30
    
    - name: ğŸ’¬ Comment PR with Guard Results
      if: github.event_name == 'pull_request' && always()
      uses: actions/github-script@v6
      with:
        script: |
          const fs = require('fs');
          
          let report;
          try {
            report = JSON.parse(fs.readFileSync('guard-report.json', 'utf8'));
          } catch (e) {
            console.log('No guard report found');
            return;
          }
          
          const violations = report.violations;
          const stats = report.statistics;
          const total = violations.length;
          const critical = violations.filter(v => 
            ['HARDCODED_SECRET', 'CROSS_IMPORT_VIOLATION'].includes(v.type)
          ).length;
          
          const status = total === 0 ? 'âœ… PASSED' : 'âŒ FAILED';
          const emoji = total === 0 ? 'ğŸŸ¢' : critical > 0 ? 'ğŸ”´' : 'ğŸŸ¡';
          
          let body = `
          ## ${emoji} Repository Guard Report ${status}
          
          **Security & Quality Scan Results:**
          
          | Metric | Count |
          |--------|-------|
          | ğŸ“ Files Scanned | ${stats.files_scanned} |
          | ğŸ”’ Security Violations | ${stats.security_violations} |
          | ğŸš« Separation Violations | ${stats.separation_violations} |
          | ğŸ“ Placeholder Content | ${stats.placeholder_violations} |
          | ğŸ“‚ Empty Files | ${stats.empty_files} |
          | **ğŸ¯ Total Violations** | **${total}** |
          | **âš ï¸ Critical Issues** | **${critical}** |
          
          `;
          
          if (critical > 0) {
            body += `
          ### ğŸš¨ Critical Violations (Build Failing)
          
          `;
            violations.filter(v => 
              ['HARDCODED_SECRET', 'CROSS_IMPORT_VIOLATION'].includes(v.type)
            ).slice(0, 5).forEach(v => {
              body += `- **${v.type}**: ${v.description} in \`${v.file}\`\n`;
            });
          }
          
          if (total > 0 && critical === 0) {
            body += `
          ### ğŸ“‹ Top Issues to Address
          
          `;
            const grouped = violations.reduce((acc, v) => {
              acc[v.type] = (acc[v.type] || 0) + 1;
              return acc;
            }, {});
            
            Object.entries(grouped)
              .sort(([,a], [,b]) => b - a)
              .slice(0, 3)
              .forEach(([type, count]) => {
                body += `- **${type}**: ${count} issues\n`;
              });
          }
          
          body += `
          
          ### ğŸ“– Repository Structure
          
          âœ… **Enforced Boundaries:**
          - \`myhibachi-frontend/\` - Next.js Frontend (Port 3000)
          - \`myhibachi-backend-fastapi/\` - FastAPI Backend (Port 8000)  
          - \`myhibachi-backend/\` - Legacy Backend (Port 8001) ğŸš« **DEPRECATED**
          - \`myhibachi-ai-backend/\` - AI Backend (Port 8002)
          
          ğŸ’¡ **Quality Gates:** ${critical > 0 ? 'ğŸ”´ Critical violations block deployment' : 'ğŸŸ¢ All critical checks passed'}
          `;
          
          github.rest.issues.createComment({
            issue_number: context.issue.number,
            owner: context.repo.owner,
            repo: context.repo.repo,
            body: body
          });

  # Job 2: Frontend Build & Test
  frontend-build:
    name: ğŸ¨ Frontend Build
    runs-on: ubuntu-latest
    needs: repository-guard
    if: needs.repository-guard.outputs.critical_violations == '0'
    defaults:
      run:
        working-directory: myhibachi-frontend
    
    steps:
    - name: ğŸ“¥ Checkout
      uses: actions/checkout@v4
    
    - name: ğŸ“¦ Setup Node.js
      uses: actions/setup-node@v4
      with:
        node-version: '18'
        cache: 'npm'
        cache-dependency-path: myhibachi-frontend/package-lock.json
    
    - name: ğŸ“¦ Install Dependencies
      run: npm ci
    
    - name: ğŸ”§ Build Frontend
      run: npm run build
    
    - name: ğŸ§ª Run Tests
      run: npm test -- --passWithNoTests
    
    - name: ğŸ“Š Upload Build Artifacts
      uses: actions/upload-artifact@v3
      with:
        name: frontend-build
        path: myhibachi-frontend/.next
        retention-days: 7

  # Job 3: FastAPI Backend Build & Test
  fastapi-backend-build:
    name: âš¡ FastAPI Backend Build
    runs-on: ubuntu-latest
    needs: repository-guard
    if: needs.repository-guard.outputs.critical_violations == '0'
    defaults:
      run:
        working-directory: myhibachi-backend-fastapi
    
    steps:
    - name: ğŸ“¥ Checkout
      uses: actions/checkout@v4
    
    - name: ğŸ Setup Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
    
    - name: ğŸ“¦ Install Dependencies
      run: |
        pip install -r requirements.txt || echo "No requirements.txt found"
        pip install fastapi uvicorn pytest httpx
    
    - name: ğŸ§ª Run Tests
      run: |
        if [ -f "test_main.py" ]; then
          pytest test_main.py -v
        else
          echo "No tests found, skipping..."
        fi
    
    - name: ğŸ” API Health Check
      run: |
        python -c "
        import sys
        import importlib.util
        
        try:
            spec = importlib.util.spec_from_file_location('main', 'main.py')
            main = importlib.util.module_from_spec(spec)
            spec.loader.exec_module(main)
            print('âœ… FastAPI app loads successfully')
        except Exception as e:
            print(f'âŒ FastAPI app failed to load: {e}')
            sys.exit(1)
        "

  # Job 4: AI Backend Isolation Check
  ai-backend-isolation:
    name: ğŸ¤– AI Backend Isolation
    runs-on: ubuntu-latest
    needs: repository-guard
    if: needs.repository-guard.outputs.critical_violations == '0'
    defaults:
      run:
        working-directory: myhibachi-ai-backend
    
    steps:
    - name: ğŸ“¥ Checkout
      uses: actions/checkout@v4
    
    - name: ğŸ Setup Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
    
    - name: ğŸ” Verify Stripe Isolation
      run: |
        echo "ğŸ” Checking AI backend for Stripe contamination..."
        
        # Check for forbidden Stripe imports
        if grep -r "import.*stripe" . --include="*.py" 2>/dev/null; then
          echo "âŒ Found Stripe imports in AI backend!"
          exit 1
        fi
        
        # Check for forbidden environment variables
        if grep -r "STRIPE_SECRET_KEY\|STRIPE_WEBHOOK_SECRET" . --include="*.py" 2>/dev/null; then
          echo "âŒ Found Stripe secrets in AI backend!"
          exit 1
        fi
        
        echo "âœ… AI backend properly isolated from Stripe"
    
    - name: ğŸ§ª AI Service Health Check
      run: |
        if [ -f "main.py" ]; then
          python -c "
          import sys
          import importlib.util
          
          try:
              spec = importlib.util.spec_from_file_location('main', 'main.py')
              main = importlib.util.module_from_spec(spec)
              spec.loader.exec_module(main)
              print('âœ… AI backend loads successfully')
          except Exception as e:
              print(f'âŒ AI backend failed to load: {e}')
              # Don't fail build for AI backend issues
              print('âš ï¸ Continuing build...')
          "
        else
          echo "â„¹ï¸ No main.py found in AI backend"
        fi

  # Job 5: Cross-Service Integration Check
  integration-test:
    name: ğŸ”— Integration Tests
    runs-on: ubuntu-latest
    needs: [repository-guard, frontend-build, fastapi-backend-build]
    if: always() && needs.repository-guard.outputs.critical_violations == '0'
    
    steps:
    - name: ğŸ“¥ Checkout
      uses: actions/checkout@v4
    
    - name: ğŸ Setup Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
    
    - name: ğŸ“¦ Setup Node.js
      uses: actions/setup-node@v4
      with:
        node-version: '18'
    
    - name: ğŸ” Port Configuration Check
      run: |
        echo "ğŸ” Verifying port assignments..."
        
        # Expected ports:
        # Frontend: 3000
        # FastAPI Backend: 8000  
        # Legacy Backend: 8001 (deprecated)
        # AI Backend: 8002
        
        python -c "
        import re
        import sys
        from pathlib import Path
        
        def check_ports(folder, expected_port, patterns):
            violations = []
            for pattern in patterns:
                for file in Path(folder).rglob('*'):
                    if file.is_file() and file.suffix in ['.py', '.js', '.ts', '.json']:
                        try:
                            content = file.read_text(encoding='utf-8', errors='ignore')
                            for match in re.finditer(pattern, content, re.IGNORECASE):
                                port = int(match.group(1))
                                if port != expected_port and port in [3000, 8000, 8001, 8002]:
                                    violations.append(f'{file}: Port {port} should be {expected_port}')
                        except:
                            pass
            return violations
        
        port_patterns = [
            r'PORT[\"\\']?\s*[:=]\s*(\d+)',
            r'port[\"\\']?\s*[:=]\s*(\d+)',
            r'listen\s*\(\s*(\d+)',
        ]
        
        checks = [
            ('myhibachi-frontend', 3000),
            ('myhibachi-backend-fastapi', 8000),
            ('myhibachi-backend', 8001),
            ('myhibachi-ai-backend', 8002),
        ]
        
        all_good = True
        for folder, expected_port in checks:
            if Path(folder).exists():
                violations = check_ports(folder, expected_port, port_patterns)
                if violations:
                    print(f'âŒ Port violations in {folder}:')
                    for v in violations[:3]:  # Show first 3
                        print(f'  {v}')
                    all_good = False
                else:
                    print(f'âœ… {folder}: Port {expected_port} correctly configured')
        
        if not all_good:
            print('ğŸ’¡ Fix port assignments to match expected values')
            sys.exit(1)
        else:
            print('ğŸ¯ All port assignments correct!')
        "

  # Job 6: Deployment Readiness
  deployment-readiness:
    name: ğŸš€ Deployment Readiness
    runs-on: ubuntu-latest
    needs: [repository-guard, frontend-build, fastapi-backend-build, ai-backend-isolation, integration-test]
    if: always()
    
    steps:
    - name: ğŸ“Š Generate Deployment Report
      run: |
        echo "## ğŸš€ Deployment Readiness Report" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        
        # Check job results
        GUARD_RESULT="${{ needs.repository-guard.result }}"
        FRONTEND_RESULT="${{ needs.frontend-build.result }}"
        BACKEND_RESULT="${{ needs.fastapi-backend-build.result }}"
        AI_RESULT="${{ needs.ai-backend-isolation.result }}"
        INTEGRATION_RESULT="${{ needs.integration-test.result }}"
        
        echo "| Component | Status | Notes |" >> $GITHUB_STEP_SUMMARY
        echo "|-----------|--------|-------|" >> $GITHUB_STEP_SUMMARY
        
        # Repository Guard
        if [ "$GUARD_RESULT" = "success" ]; then
          echo "| ğŸ›¡ï¸ Repository Guard | âœ… PASSED | Security checks passed |" >> $GITHUB_STEP_SUMMARY
        else
          echo "| ğŸ›¡ï¸ Repository Guard | âŒ FAILED | Critical violations found |" >> $GITHUB_STEP_SUMMARY
        fi
        
        # Frontend
        if [ "$FRONTEND_RESULT" = "success" ]; then
          echo "| ğŸ¨ Frontend Build | âœ… PASSED | Ready for deployment |" >> $GITHUB_STEP_SUMMARY
        elif [ "$FRONTEND_RESULT" = "skipped" ]; then
          echo "| ğŸ¨ Frontend Build | â­ï¸ SKIPPED | Blocked by guard failures |" >> $GITHUB_STEP_SUMMARY
        else
          echo "| ğŸ¨ Frontend Build | âŒ FAILED | Build or test failures |" >> $GITHUB_STEP_SUMMARY
        fi
        
        # FastAPI Backend
        if [ "$BACKEND_RESULT" = "success" ]; then
          echo "| âš¡ FastAPI Backend | âœ… PASSED | Ready for deployment |" >> $GITHUB_STEP_SUMMARY
        elif [ "$BACKEND_RESULT" = "skipped" ]; then
          echo "| âš¡ FastAPI Backend | â­ï¸ SKIPPED | Blocked by guard failures |" >> $GITHUB_STEP_SUMMARY
        else
          echo "| âš¡ FastAPI Backend | âŒ FAILED | Build or test failures |" >> $GITHUB_STEP_SUMMARY
        fi
        
        # AI Backend
        if [ "$AI_RESULT" = "success" ]; then
          echo "| ğŸ¤– AI Backend | âœ… PASSED | Properly isolated |" >> $GITHUB_STEP_SUMMARY
        elif [ "$AI_RESULT" = "skipped" ]; then
          echo "| ğŸ¤– AI Backend | â­ï¸ SKIPPED | Blocked by guard failures |" >> $GITHUB_STEP_SUMMARY
        else
          echo "| ğŸ¤– AI Backend | âš ï¸ WARNING | Isolation issues detected |" >> $GITHUB_STEP_SUMMARY
        fi
        
        # Integration
        if [ "$INTEGRATION_RESULT" = "success" ]; then
          echo "| ğŸ”— Integration Tests | âœ… PASSED | Cross-service checks passed |" >> $GITHUB_STEP_SUMMARY
        elif [ "$INTEGRATION_RESULT" = "skipped" ]; then
          echo "| ğŸ”— Integration Tests | â­ï¸ SKIPPED | Prerequisites failed |" >> $GITHUB_STEP_SUMMARY
        else
          echo "| ğŸ”— Integration Tests | âŒ FAILED | Port or config issues |" >> $GITHUB_STEP_SUMMARY
        fi
        
        echo "" >> $GITHUB_STEP_SUMMARY
        
        # Overall status
        if [ "$GUARD_RESULT" = "success" ] && [ "$FRONTEND_RESULT" = "success" ] && [ "$BACKEND_RESULT" = "success" ]; then
          echo "### ğŸ¯ Overall Status: âœ… READY FOR DEPLOYMENT" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Next Steps:**" >> $GITHUB_STEP_SUMMARY
          echo "1. Deploy FastAPI backend to production" >> $GITHUB_STEP_SUMMARY  
          echo "2. Update frontend environment variables" >> $GITHUB_STEP_SUMMARY
          echo "3. Deploy frontend to Vercel/Netlify" >> $GITHUB_STEP_SUMMARY
          echo "4. Run smoke tests" >> $GITHUB_STEP_SUMMARY
        else
          echo "### ğŸ”´ Overall Status: âŒ NOT READY FOR DEPLOYMENT" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Blockers must be resolved before deployment.**" >> $GITHUB_STEP_SUMMARY
        fi
        
        # Set workflow status
        if [ "$GUARD_RESULT" != "success" ]; then
          echo "âŒ Deployment blocked by repository guard failures"
          exit 1
        fi

# Reusable workflow for manual deployment
  manual-deploy:
    name: ğŸ¯ Manual Deploy Trigger
    runs-on: ubuntu-latest
    if: github.event_name == 'workflow_dispatch' && needs.deployment-readiness.result == 'success'
    needs: deployment-readiness
    environment: production
    
    steps:
    - name: ğŸš€ Deploy to Production
      run: |
        echo "ğŸš€ Manual deployment triggered!"
        echo "This would trigger your actual deployment scripts"
        echo "- Deploy FastAPI backend"
        echo "- Update environment variables"  
        echo "- Deploy frontend"
        echo "- Run smoke tests"
