# Comprehensive Testing Guide

**Last Updated:** October 25, 2025  
**Version:** 2.0  
**Status:** âœ… Production Ready

---

## ğŸ“‹ Table of Contents

1. [Overview](#overview)
2. [Testing Infrastructure](#testing-infrastructure)
3. [Quick Start](#quick-start)
4. [Backend Testing](#backend-testing)
5. [Frontend Testing](#frontend-testing)
6. [API Testing](#api-testing)
7. [Manual Testing](#manual-testing)
8. [Performance Testing](#performance-testing)
9. [Test Coverage](#test-coverage)
10. [CI/CD Integration](#cicd-integration)
11. [Troubleshooting](#troubleshooting)

---

## Overview

### Testing Philosophy

Our testing strategy follows the **Test Pyramid** approach:

- **70% Unit Tests** - Fast, isolated component tests
- **20% Integration Tests** - API and database interaction tests
- **10% E2E Tests** - Full user flow validation

### Current Coverage

| Component             | Unit Tests         | Integration Tests | E2E Tests  | Coverage % |
| --------------------- | ------------------ | ----------------- | ---------- | ---------- |
| **Backend API**       | âœ… 50+ tests       | âœ… 18 tests       | â³ Planned | 87%        |
| **Frontend Customer** | âœ… 17 tests        | â³ In Progress    | â³ Planned | 68%        |
| **Frontend Admin**    | â³ Planned         | â³ Planned        | â³ Planned | 45%        |
| **Database**          | âœ… Via Integration | âœ… Tested         | N/A        | 92%        |
| **Services**          | âœ… 25 tests        | âœ… 12 tests       | N/A        | 85%        |

### Testing Tools

#### Backend (Python/FastAPI)

- **Framework:** Pytest 7.4+
- **Async Support:** pytest-asyncio
- **HTTP Client:** httpx
- **Database:** SQLAlchemy with PostgreSQL
- **Mocking:** pytest-mock, faker
- **Performance:** pytest-benchmark

#### Frontend (TypeScript/Next.js)

- **Framework:** Vitest with jsdom
- **Component Testing:** @testing-library/react
- **User Interaction:** @testing-library/user-event
- **Coverage:** @vitest/coverage-v8
- **Mocking:** vi.fn(), vi.mock()

#### API Testing

- **Interactive:** Postman/Bruno
- **Automated:** Pytest + httpx
- **Load Testing:** Apache Bench, K6
- **Performance:** Custom benchmarks

---

## Testing Infrastructure

### Project Structure

```
apps/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ tests/
â”‚   â”‚   â”œâ”€â”€ conftest.py                      # Test fixtures & configuration
â”‚   â”‚   â”œâ”€â”€ test_newsletter_unit.py          # Newsletter unit tests
â”‚   â”‚   â”œâ”€â”€ test_newsletter_integration.py   # Newsletter integration tests
â”‚   â”‚   â”œâ”€â”€ test_api_performance.py          # Performance validation
â”‚   â”‚   â”œâ”€â”€ test_api_cursor_pagination.py    # Cursor pagination tests
â”‚   â”‚   â”œâ”€â”€ test_api_cte_queries.py          # CTE query tests
â”‚   â”‚   â””â”€â”€ test_api_load.py                 # Load & stress tests
â”‚   â””â”€â”€ pytest.ini                           # Pytest configuration
â”‚
â”œâ”€â”€ customer/
â”‚   â”œâ”€â”€ src/test/
â”‚   â”‚   â”œâ”€â”€ setup.ts                         # Vitest setup
â”‚   â”‚   â””â”€â”€ components/
â”‚   â”‚       â””â”€â”€ QuoteRequestForm.test.tsx    # Component tests
â”‚   â””â”€â”€ vitest.config.ts                     # Vitest configuration
â”‚
â””â”€â”€ admin/
    â””â”€â”€ tests/                               # Admin panel tests (planned)

tests/
â”œâ”€â”€ postman/                                 # Postman collections
â”‚   â”œâ”€â”€ MyHibachi_API_Performance_Tests.postman_collection.json
â”‚   â”œâ”€â”€ Development.postman_environment.json
â”‚   â””â”€â”€ Production.postman_environment.json
â””â”€â”€ bruno/                                   # Bruno collections (optional)
```

### Environment Setup

#### Backend Testing Environment

**Prerequisites:**

```powershell
# PostgreSQL 14+
choco install postgresql14 -y

# Python 3.11+
python --version  # Should be 3.11 or higher
```

**Configuration (apps/backend/.env.test):**

```env
DATABASE_URL=postgresql://myhibachi_user:password@localhost:5432/myhibachi_test
ENVIRONMENT=test
LOG_LEVEL=DEBUG
JWT_SECRET=test_secret_key_for_testing_only
SMS_ENABLED=false
EMAIL_ENABLED=false
```

**Install Dependencies:**

```powershell
cd apps/backend
pip install -r requirements.txt
pip install pytest pytest-asyncio httpx pytest-benchmark faker pytest-cov pytest-mock
```

#### Frontend Testing Environment

**Install Dependencies:**

```powershell
cd apps/customer
npm install --save-dev vitest @vitest/ui @vitest/coverage-v8 jsdom
npm install --save-dev @testing-library/react @testing-library/user-event @testing-library/jest-dom
```

---

## Quick Start

### Run All Tests (Fastest)

```powershell
# Backend tests (from project root)
cd apps/backend
pytest tests/ -v --tb=short

# Frontend tests (from project root)
cd apps/customer
npm test

# Run everything in parallel (from project root)
# PowerShell parallel execution
Start-Job { cd apps/backend; pytest tests/ -v }
Start-Job { cd apps/customer; npm test }
Get-Job | Wait-Job | Receive-Job
```

### Run Specific Test Suites

```powershell
# Backend: Unit tests only
pytest tests/test_newsletter_unit.py -v -m unit

# Backend: Integration tests only
pytest tests/test_newsletter_integration.py -v -m integration

# Backend: Performance tests only
pytest tests/test_api_performance.py -v -m performance

# Backend: Smoke tests (critical paths)
pytest tests/ -v -m smoke

# Frontend: Watch mode (re-run on file changes)
cd apps/customer
npm test -- --watch

# Frontend: Single component
npm test QuoteRequestForm.test.tsx
```

### Quick Health Check (30 seconds)

```powershell
# Backend smoke tests
cd apps/backend
pytest tests/ -v -m smoke

# Frontend quick check
cd apps/customer
npm test -- --run

# Expected output:
# Backend: 3/3 smoke tests PASSED
# Frontend: 17/17 tests PASSED
```

---

## Backend Testing

### Unit Tests

#### Newsletter Service Unit Tests (`test_newsletter_unit.py`)

**Coverage:** 25 test cases

**Test Classes:**

1. **TestSubscribeMethod** (5 tests)
   - Subscribe with phone only
   - Subscribe with phone + email
   - Fail without phone (required field)
   - Handle database exceptions
   - Validate subscription sources

2. **TestUnsubscribeMethod** (3 tests)
   - Unsubscribe existing subscriber
   - Handle nonexistent subscriber
   - Idempotent unsubscribe

3. **TestResubscribeMethod** (2 tests)
   - Resubscribe unsubscribed user
   - Handle nonexistent subscriber

4. **TestPhoneNumberCleaning** (3 tests)
   - Remove formatting: (555) 123-4567 â†’ 5551234567
   - Handle various formats
   - Handle empty/None input

5. **TestWelcomeMessages** (4 tests)
   - Send welcome SMS successfully
   - Handle SMS API failure gracefully
   - Send welcome email successfully
   - Handle email API failure gracefully

6. **TestErrorHandling** (2 tests)
   - Continue processing if SMS fails
   - Continue processing if email fails

7. **TestSubscriptionSources** (6 tests)
   - Quote form source
   - Booking form source
   - Manual admin source
   - API import source
   - Webhook source
   - Migration source

**Run Commands:**

```powershell
# Run all unit tests
pytest tests/test_newsletter_unit.py -v -m unit

# Run specific test class
pytest tests/test_newsletter_unit.py::TestSubscribeMethod -v

# Run with detailed output
pytest tests/test_newsletter_unit.py -v -s

# Run with coverage report
pytest tests/test_newsletter_unit.py --cov=app.services.newsletter_service --cov-report=html
```

**Expected Output:**

```
tests/test_newsletter_unit.py::TestSubscribeMethod::test_subscribe_with_phone_only PASSED
tests/test_newsletter_unit.py::TestSubscribeMethod::test_subscribe_with_phone_and_email PASSED
tests/test_newsletter_unit.py::TestSubscribeMethod::test_subscribe_without_phone_fails PASSED
...
======================== 25 passed in 3.45s ========================
```

---

### Integration Tests

#### Newsletter Integration Tests (`test_newsletter_integration.py`)

**Coverage:** 18 test cases

**Test Classes:**

1. **TestQuoteFormIntegration** (4 tests)
   - Create lead and auto-subscribe
   - Work without email (phone-only)
   - Block spam with honeypot
   - Validate required fields

2. **TestBookingFormIntegration** (6 tests)
   - Create booking lead and auto-subscribe
   - Accept various time formats
   - Reject past dates
   - Block spam with honeypot
   - Validate guest count (1-50)
   - Handle missing fields

3. **TestPhoneNumberFormatting** (2 tests)
   - Accept: (555) 123-4567, 555-123-4567, 5551234567, +15551234567
   - Reject: invalid formats

4. **TestEndToEndFlow** (1 test)
   - Quote form submission â†’ Lead created â†’ Newsletter subscribed
   - Booking form submission â†’ Booking created â†’ Newsletter subscribed
   - Complete journey validation

5. **TestPerformanceTargets** (2 tests)
   - Quote form: <1000ms response time
   - Booking form: <1500ms response time

6. **TestSmokeTests** (3 tests)
   - Quote form basic functionality
   - Booking form basic functionality
   - Health check endpoint

**Run Commands:**

```powershell
# Run all integration tests
pytest tests/test_newsletter_integration.py -v -m integration

# Run smoke tests only (critical paths)
pytest tests/test_newsletter_integration.py -v -m smoke

# Run performance tests
pytest tests/test_newsletter_integration.py -v -m performance

# Run all newsletter tests (unit + integration)
pytest tests/test_newsletter_*.py -v --tb=short
```

**Expected Output:**

```
tests/test_newsletter_integration.py::TestQuoteFormIntegration::test_create_lead_and_subscribe PASSED [120ms]
tests/test_newsletter_integration.py::TestBookingFormIntegration::test_create_booking_and_subscribe PASSED [150ms]
tests/test_newsletter_integration.py::TestPerformanceTargets::test_quote_form_performance PASSED [85ms]
...
======================== 18 passed in 5.23s ========================
```

---

### Performance Tests

#### API Performance Tests (`test_api_performance.py`)

**Coverage:** 10 test cases

**Performance Targets:**

| Endpoint           | Original  | Target    | Improvement    |
| ------------------ | --------- | --------- | -------------- |
| Cursor Pagination  | 50ms      | <20ms     | 2.5x faster    |
| Payment Analytics  | 200ms     | <15ms     | 13x faster     |
| Booking KPIs       | 300ms     | <17ms     | 18x faster     |
| Customer Analytics | 250ms     | <20ms     | 12x faster     |
| **Combined**       | **790ms** | **<80ms** | **10x faster** |

**Test Classes:**

1. **TestCursorPaginationPerformance** (3 tests)
   - First page <20ms
   - Subsequent pages <20ms
   - O(1) scalability validation

2. **TestCTEQueryPerformance** (3 tests)
   - Payment analytics <15ms
   - Booking KPIs <17ms
   - Customer analytics <20ms

3. **TestScalabilityPerformance** (2 tests)
   - Cursor pagination: 100â†’500â†’1000 records
   - CTE queries: Logarithmic scaling

4. **TestPerformanceRegression** (2 tests)
   - No N+1 queries
   - Overall 10x improvement maintained

**Run Commands:**

```powershell
# Run all performance tests
pytest tests/test_api_performance.py -v

# Run with benchmark comparison
pytest tests/test_api_performance.py -v --benchmark-only

# Run with detailed timing
pytest tests/test_api_performance.py -v -s --durations=10
```

**Expected Output:**

```
tests/test_api_performance.py::test_first_page_performance PASSED
âœ… First page: 12.4ms (target: <20ms, 4.2x improvement)

tests/test_api_performance.py::test_payment_analytics_performance PASSED
âœ… Payment analytics: 10.8ms (target: <15ms, 18.5x improvement)

======================== Performance Summary ========================
Endpoint                          | Response Time | Target | Status
----------------------------------|---------------|--------|--------
GET /api/bookings (cursor)        | 12.4ms        | <20ms  | âœ… PASS
GET /api/payments/analytics       | 10.8ms        | <15ms  | âœ… PASS
GET /api/admin/kpis               | 13.2ms        | <17ms  | âœ… PASS
GET /api/admin/customer-analytics | 16.5ms        | <20ms  | âœ… PASS

Overall improvement: 11.8x faster (790ms â†’ 67ms)
======================== 10 passed in 8.45s ========================
```

---

### Load Tests

#### Concurrent Load Tests (`test_api_load.py`)

**Coverage:** 12 test cases

**Load Test Scenarios:**

1. **Concurrent Request Handling**
   - 50 concurrent cursor pagination requests
   - 30 concurrent CTE analytics requests
   - 60 mixed concurrent requests

2. **Connection Pool Management**
   - 100 sequential requests (no pool exhaustion)
   - 100 concurrent requests (stress test)

3. **Throughput Measurement**
   - Cursor pagination: >20 req/sec
   - CTE analytics: >10 req/sec

4. **Error Rate Monitoring**
   - Normal load: <5% error rate
   - Heavy load: <20% error rate
   - Recovery after errors

**Run Commands:**

```powershell
# Run load tests (WARNING: Takes 2-3 minutes)
pytest tests/test_api_load.py -v -m slow

# Run only quick load tests
pytest tests/test_api_load.py -v -m "not slow"

# Run with concurrency report
pytest tests/test_api_load.py -v -s
```

**Expected Output:**

```
tests/test_api_load.py::test_concurrent_cursor_pagination_requests PASSED
âœ… Concurrent pagination: 50/50 succeeded (100.0%)
   Average response time: 15.32ms

tests/test_api_load.py::test_cursor_pagination_throughput PASSED
âœ… Throughput: 45.2 req/sec (target: >20 req/sec)

======================== 12 passed in 145.67s ========================
```

---

### Test Fixtures (`conftest.py`)

**Key Fixtures:**

#### Database Fixtures

```python
@pytest.fixture
async def test_db_engine():
    """SQLAlchemy async engine for testing"""
    # In-memory SQLite or PostgreSQL test database

@pytest.fixture
async def test_db_session(test_db_engine):
    """Async database session with automatic rollback"""

@pytest.fixture
def override_db_dependency(test_db_session):
    """Override FastAPI DB dependency"""
```

#### HTTP Client Fixtures

```python
@pytest.fixture
async def async_client(app, override_db_dependency):
    """Async HTTP client for API testing"""

@pytest.fixture
async def auth_client(async_client, mock_admin_user):
    """Pre-authenticated admin client"""
```

#### Authentication Fixtures

```python
@pytest.fixture
def mock_admin_user():
    """Admin user with all permissions"""
    return {
        "id": 1,
        "email": "admin@test.com",
        "role": "admin",
        "station_id": 1
    }
```

#### Sample Data Fixtures

```python
@pytest.fixture
async def create_test_bookings(test_db_session):
    """Generate N realistic test bookings"""

@pytest.fixture
async def create_test_payments(test_db_session):
    """Generate N realistic test payments"""
```

#### Performance Fixtures

```python
@pytest.fixture
def performance_tracker():
    """Track and validate response times"""
```

---

## Frontend Testing

### Component Unit Tests

#### Quote Request Form Tests (`QuoteRequestForm.test.tsx`)

**Coverage:** 17 test cases

**Test Groups:**

1. **Auto-Subscribe Notice Display** (3 tests)
   - Display auto-subscribe notice
   - No consent checkboxes (removed)
   - Display STOP instructions

2. **Form Validation** (4 tests)
   - Require name field
   - Require phone field
   - Email is optional
   - Validate phone format

3. **Form Submission** (4 tests)
   - Submit with valid data
   - Submit with phone-only (no email)
   - Include source field in payload
   - Display success message
   - Display error message on failure

4. **Loading States** (2 tests)
   - Show loading indicator during submission
   - Disable form during submission

5. **Honeypot Protection** (2 tests)
   - Include hidden honeypot field
   - Block submission if honeypot filled

6. **Phone Number Formatting** (2 tests)
   - Accept various formats: (555) 123-4567, 555-123-4567, etc.
   - Real-time formatting

**Run Commands:**

```powershell
cd apps/customer

# Run all tests
npm test

# Run in watch mode (re-run on changes)
npm test -- --watch

# Run specific test file
npm test QuoteRequestForm.test.tsx

# Run with coverage
npm run test:coverage

# Run with UI (browser-based test viewer)
npm run test:ui
```

**Expected Output:**

```
âœ“ src/test/components/QuoteRequestForm.test.tsx (17)
  âœ“ Auto-Subscribe Notice (3)
    âœ“ displays auto-subscribe notice
    âœ“ does not show consent checkboxes
    âœ“ displays STOP instructions
  âœ“ Form Validation (4)
    âœ“ requires name field
    âœ“ requires phone field
    âœ“ email is optional
    âœ“ validates phone format
  ...

Test Files  1 passed (1)
     Tests  17 passed (17)
  Start at  14:23:45
  Duration  2.34s
```

---

### Frontend Test Configuration

#### Vitest Configuration (`vitest.config.ts`)

```typescript
import { defineConfig } from 'vitest/config';
import react from '@vitejs/plugin-react';
import path from 'path';

export default defineConfig({
  plugins: [react()],
  test: {
    environment: 'jsdom',
    setupFiles: ['./src/test/setup.ts'],
    globals: true,
    coverage: {
      provider: 'v8',
      reporter: ['text', 'json', 'html'],
      include: ['src/components/**/*.tsx', 'src/lib/**/*.ts'],
      exclude: ['src/test/**', '**/*.test.tsx'],
      thresholds: {
        global: {
          statements: 85,
          branches: 85,
          functions: 85,
          lines: 85,
        },
      },
    },
  },
  resolve: {
    alias: {
      '@': path.resolve(__dirname, './src'),
    },
  },
});
```

#### Test Setup (`src/test/setup.ts`)

```typescript
import '@testing-library/jest-dom';
import { cleanup } from '@testing-library/react';
import { afterEach, vi } from 'vitest';

// Cleanup after each test
afterEach(() => {
  cleanup();
});

// Mock Next.js router
vi.mock('next/navigation', () => ({
  useRouter: () => ({
    push: vi.fn(),
    replace: vi.fn(),
    back: vi.fn(),
  }),
}));

// Mock fetch globally
global.fetch = vi.fn();
```

---

## API Testing

### Postman Collection

#### Setup

**Import Collection:**

1. Open Postman Desktop
2. Click "Import"
3. Select
   `tests/postman/MyHibachi_API_Performance_Tests.postman_collection.json`
4. Select environment file: `Development.postman_environment.json`
5. Click "Import"

**Configure Environment:**

1. Select "Development" environment
2. Update variables:
   - `base_url`: http://localhost:8000
   - `admin_token`: Get from login endpoint
   - `test_customer_email`: test@example.com

**Get Admin Token:**

```powershell
curl -X POST http://localhost:8000/api/auth/login `
  -H "Content-Type: application/json" `
  -d '{\"email\": \"admin@myhibachi.com\", \"password\": \"your_password\"}'
```

#### Collection Structure

```
MyHibachi_API_Performance_Tests
â”œâ”€â”€ Cursor Pagination (3 requests)
â”‚   â”œâ”€â”€ Get First Page
â”‚   â”œâ”€â”€ Get Second Page (with cursor)
â”‚   â””â”€â”€ Backward Navigation
â”‚
â”œâ”€â”€ CTE Analytics (3 requests)
â”‚   â”œâ”€â”€ Payment Analytics (30 days)
â”‚   â”œâ”€â”€ Booking KPIs
â”‚   â””â”€â”€ Customer Analytics
â”‚
â””â”€â”€ Load Testing (1 request)
    â””â”€â”€ Concurrent Pagination Test (run 100x)
```

#### Run Collection

**Manual Run:**

1. Right-click collection
2. Select "Run collection"
3. Choose environment
4. Click "Run"

**Newman (CLI):**

```powershell
# Install Newman
npm install -g newman

# Run collection
newman run tests/postman/MyHibachi_API_Performance_Tests.postman_collection.json `
  -e tests/postman/Development.postman_environment.json `
  --reporters cli,html `
  --reporter-html-export test-results.html
```

**Expected Output:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    MyHibachi API Performance Tests                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Cursor Pagination                                                   â”‚
â”‚   âœ… Get First Page                                      12ms       â”‚
â”‚      âœ“ Response time under 20ms                                     â”‚
â”‚      âœ“ Has items array                                              â”‚
â”‚                                                                      â”‚
â”‚ CTE Analytics                                                        â”‚
â”‚   âœ… Payment Analytics (30 days)                        11ms       â”‚
â”‚      âœ“ Response time under 15ms (20x improvement)                   â”‚
â”‚      âœ“ Has required fields                                          â”‚
â”‚                                                                      â”‚
â”‚ âœ… All tests passed (20/20)                                         â”‚
â”‚ âœ… Total time: 67ms (target: <80ms)                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

### Bruno Collection (Alternative)

**Advantages:**

- âœ… Open source, no account required
- âœ… Git-friendly (stores as text files)
- âœ… Faster and lighter than Postman
- âœ… Privacy-focused (no cloud sync)

**Setup:**

1. Install Bruno: https://www.usebruno.com/
2. Open Bruno
3. Click "Open Collection"
4. Select `tests/bruno/` folder
5. Configure environment variables

---

## Manual Testing

### Pre-Testing Checklist

**Backend:**

- [ ] PostgreSQL running
- [ ] Database migrations applied
- [ ] Test data seeded
- [ ] Dev server running on port 8000
- [ ] No console errors in terminal

**Frontend:**

- [ ] Node.js dependencies installed
- [ ] Dev server running on port 3000
- [ ] Production build succeeds
- [ ] TypeScript strict mode: 0 errors
- [ ] ESLint: 0 errors

### Manual Test Cases

#### Test 1: Client-Side Cache (Blog Page)

**Steps:**

1. Open Chrome DevTools â†’ Console
2. Navigate to http://localhost:3000/blog
3. **First load:** Console shows "Cache miss"
4. Navigate away and back
5. **Second load:** Console shows "Cache hit"
6. Verify: Load time <10ms (instant)

**Expected:**

- âœ… Cache miss on first visit
- âœ… Cache hit on subsequent visits
- âœ… 99% faster load time
- âœ… No console errors

---

#### Test 2: Quote Form Submission

**Steps:**

1. Navigate to http://localhost:3000/BookUs
2. Fill out quote request form:
   - Name: John Doe
   - Phone: (555) 123-4567
   - Email: john@example.com (optional)
3. Submit form
4. Verify success message

**Expected:**

- âœ… Form submits successfully
- âœ… Success message displays
- âœ… User auto-subscribed to newsletter
- âœ… No console errors

---

#### Test 3: Booking Form Submission

**Steps:**

1. Navigate to http://localhost:3000/BookUs
2. Fill out booking form:
   - Name: Jane Smith
   - Phone: 555-987-6543
   - Event Date: Tomorrow
   - Guest Count: 25
3. Submit form
4. Verify success message

**Expected:**

- âœ… Form submits successfully
- âœ… Booking lead created
- âœ… User auto-subscribed to newsletter
- âœ… No past date accepted
- âœ… Guest count validated (1-50)

---

#### Test 4: Honeypot Spam Protection

**Steps:**

1. Navigate to http://localhost:3000/BookUs
2. Open DevTools â†’ Elements
3. Find hidden honeypot field
4. Fill honeypot field with text
5. Submit form

**Expected:**

- âœ… Form submission blocked
- âœ… No data saved to database
- âœ… User sees generic error (or success to fool bots)

---

#### Test 5: TypeScript Strict Mode

**Steps:**

1. Open DevTools â†’ Console
2. Navigate through entire app:
   - Homepage
   - Blog
   - Book Us
   - Menu
   - Individual blog posts
3. Monitor console for errors

**Expected:**

- âœ… Zero TypeScript errors
- âœ… No "undefined" errors
- âœ… No "null" errors
- âœ… No type warnings

---

### Cache Testing (Advanced)

**Browser Console Commands:**

```javascript
// Get cache statistics
window.blogCache.getStats();
// Expected: { size: 5, hits: 12, misses: 5, hitRate: 0.71 }

// Check if specific data is cached
window.blogCache.has('featured-posts-3');
// Expected: true

// Get all cache keys
window.blogCache.keys();
// Expected: ['featured-posts-3', 'blog-posts-recent', ...]

// Manually clear cache (for testing)
window.blogCache.clear();
// Expected: Cache cleared
```

---

## Performance Testing

### Lighthouse Audit

**Run Lighthouse:**

1. Open Chrome DevTools
2. Go to "Lighthouse" tab
3. Select categories:
   - âœ… Performance
   - âœ… Accessibility
   - âœ… Best Practices
   - âœ… SEO
4. Click "Analyze page load"

**Target Scores:**

- **Performance:** >90
- **Accessibility:** >95
- **Best Practices:** >95
- **SEO:** >90

---

### Load Testing (Apache Bench)

**Install Apache Bench:**

```powershell
# Included with Apache or install separately
choco install apache-httpd -y
```

**Run Load Test:**

```powershell
# Test cursor pagination endpoint
ab -n 1000 -c 50 -H "Authorization: Bearer YOUR_TOKEN" `
  http://localhost:8000/api/bookings?limit=20

# Expected output:
# Requests per second: 45.2
# Time per request: 22.1ms (mean)
# Time per request: 1.1ms (mean, across all concurrent requests)
```

---

### K6 Load Testing (Advanced)

**Install K6:**

```powershell
choco install k6 -y
```

**Create Test Script (k6-load-test.js):**

```javascript
import http from 'k6/http';
import { check, sleep } from 'k6';

export let options = {
  stages: [
    { duration: '30s', target: 20 }, // Ramp up to 20 users
    { duration: '1m', target: 50 }, // Stay at 50 users
    { duration: '30s', target: 0 }, // Ramp down
  ],
  thresholds: {
    http_req_duration: ['p(95)<500'], // 95% requests < 500ms
    http_req_failed: ['rate<0.05'], // <5% errors
  },
};

export default function () {
  let response = http.get(
    'http://localhost:8000/api/bookings?limit=20',
    {
      headers: { Authorization: 'Bearer YOUR_TOKEN' },
    }
  );

  check(response, {
    'status is 200': r => r.status === 200,
    'response time < 20ms': r => r.timings.duration < 20,
  });

  sleep(1);
}
```

**Run K6 Test:**

```powershell
k6 run k6-load-test.js

# Expected output:
# âœ“ status is 200
# âœ“ response time < 20ms
# http_req_duration..........: avg=12.4ms p(95)=18.2ms max=45.3ms
# http_req_failed............: 0.12%
```

---

## Test Coverage

### Current Coverage Report

#### Backend Coverage

```
Name                                    Stmts   Miss  Cover
-----------------------------------------------------------
app/services/newsletter_service.py        150     20    87%
app/services/lead_service.py              200     25    88%
app/services/booking_service.py           180     22    88%
app/api/routes/bookings.py                 95      8    92%
app/api/routes/leads.py                    80      6    93%
app/utils/query_optimizer.py               75      5    93%
-----------------------------------------------------------
TOTAL                                     780     86    89%
```

**Generate Coverage Report:**

```powershell
cd apps/backend

# Generate HTML coverage report
pytest tests/ --cov=app --cov-report=html

# Open report in browser
start htmlcov/index.html
```

---

#### Frontend Coverage

```
File                               | % Stmts | % Branch | % Funcs | % Lines
------------------------------------------------------------------------
src/components/QuoteRequestForm.tsx |   88.2  |   75.0   |   90.0  |   87.5
src/components/BookingForm.tsx      |   65.4  |   58.3   |   70.0  |   64.7
src/lib/contactData.ts              |   92.3  |   85.7   |   95.0  |   91.8
------------------------------------------------------------------------
All files                           |   68.5  |   62.1   |   72.3  |   67.9
```

**Generate Coverage Report:**

```powershell
cd apps/customer

# Generate coverage report
npm run test:coverage

# Open report in browser
start coverage/index.html
```

---

### Coverage Goals

**Critical Components (>95% required):**

- Newsletter subscription flow
- Lead creation flow
- Booking creation flow
- Phone number validation
- Authentication & authorization
- Payment processing

**Standard Components (>85% target):**

- API endpoints
- Service layer methods
- Form components
- Utility functions

**Low Priority (<70% acceptable):**

- UI components (buttons, modals)
- Static pages
- Type definitions

---

## CI/CD Integration

### GitHub Actions Workflow

**Create `.github/workflows/test.yml`:**

```yaml
name: Automated Testing

on:
  push:
    branches: [main, develop]
  pull_request:
    branches: [main]

jobs:
  backend-tests:
    name: Backend Tests (Python)
    runs-on: ubuntu-latest

    services:
      postgres:
        image: postgres:14
        env:
          POSTGRES_USER: test_user
          POSTGRES_PASSWORD: test_password
          POSTGRES_DB: myhibachi_test
        options: >-
          --health-cmd pg_isready --health-interval 10s
          --health-timeout 5s --health-retries 5
        ports:
          - 5432:5432

    steps:
      - uses: actions/checkout@v3

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'

      - name: Install dependencies
        run: |
          cd apps/backend
          pip install -r requirements.txt
          pip install pytest pytest-asyncio httpx pytest-cov faker

      - name: Run unit tests
        run: |
          cd apps/backend
          pytest tests/ -v -m unit --cov=app --cov-report=xml

      - name: Run integration tests
        run: |
          cd apps/backend
          pytest tests/ -v -m integration
        env:
          DATABASE_URL: postgresql://test_user:test_password@localhost:5432/myhibachi_test

      - name: Run smoke tests
        run: |
          cd apps/backend
          pytest tests/ -v -m smoke

      - name: Upload coverage to Codecov
        uses: codecov/codecov-action@v3
        with:
          files: ./apps/backend/coverage.xml
          flags: backend

  frontend-tests:
    name: Frontend Tests (TypeScript)
    runs-on: ubuntu-latest

    steps:
      - uses: actions/checkout@v3

      - name: Set up Node.js
        uses: actions/setup-node@v3
        with:
          node-version: '18'
          cache: 'npm'
          cache-dependency-path: apps/customer/package-lock.json

      - name: Install dependencies
        run: |
          cd apps/customer
          npm ci

      - name: Run tests
        run: |
          cd apps/customer
          npm test -- --run

      - name: Generate coverage
        run: |
          cd apps/customer
          npm run test:coverage

      - name: Upload coverage to Codecov
        uses: codecov/codecov-action@v3
        with:
          files: ./apps/customer/coverage/coverage-final.json
          flags: frontend

  performance-tests:
    name: Performance Tests
    runs-on: ubuntu-latest
    needs: [backend-tests]

    steps:
      - uses: actions/checkout@v3

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'

      - name: Install dependencies
        run: |
          cd apps/backend
          pip install -r requirements.txt
          pip install pytest pytest-asyncio httpx pytest-benchmark

      - name: Run performance tests
        run: |
          cd apps/backend
          pytest tests/test_api_performance.py -v -m performance

      - name: Check performance thresholds
        run: |
          cd apps/backend
          pytest tests/test_api_performance.py -v --benchmark-only
```

---

### Pre-Commit Hooks

**Install Pre-Commit:**

```powershell
pip install pre-commit
```

**Create `.pre-commit-config.yaml`:**

```yaml
repos:
  - repo: local
    hooks:
      - id: backend-tests
        name: Backend Unit Tests
        entry:
          bash -c 'cd apps/backend && pytest tests/ -v -m "unit and
          not slow"'
        language: system
        pass_filenames: false
        always_run: true

      - id: frontend-tests
        name: Frontend Tests
        entry: bash -c 'cd apps/customer && npm test -- --run'
        language: system
        pass_filenames: false
        always_run: true

      - id: typescript-check
        name: TypeScript Type Check
        entry: bash -c 'cd apps/customer && npm run typecheck'
        language: system
        pass_filenames: false
        always_run: true
```

**Install Hooks:**

```powershell
pre-commit install
```

---

## Troubleshooting

### Common Issues

#### Issue: "pytest: command not found"

**Solution:**

```powershell
cd apps/backend
pip install pytest pytest-asyncio httpx
pytest --version  # Verify installation
```

---

#### Issue: Database connection errors

**Solution:**

```powershell
# Check PostgreSQL status
Get-Service postgresql*

# Start if not running
Start-Service postgresql-x64-14

# Verify connection
psql -U postgres -c "SELECT version();"

# Check .env configuration
cat apps/backend/.env | Select-String "DATABASE_URL"
```

---

#### Issue: No test data (empty results)

**Solution:**

```powershell
cd apps/backend

# Run seed script
python scripts/seed_test_data.py

# Verify data
psql -U myhibachi_user -d myhibachi -c "SELECT COUNT(*) FROM bookings;"
```

---

#### Issue: Frontend tests failing with "Cannot find module"

**Solution:**

```powershell
cd apps/customer

# Clean install
rm -rf node_modules package-lock.json
npm install

# Verify Vitest installation
npx vitest --version
```

---

#### Issue: Performance targets not met

**Solution:**

```powershell
# Check database size
psql -U myhibachi_user -d myhibachi -c "
SELECT
    tablename,
    pg_size_pretty(pg_total_relation_size('public.'||tablename)) AS size
FROM pg_tables
WHERE schemaname = 'public'
ORDER BY pg_total_relation_size('public.'||tablename) DESC;
"

# Vacuum and analyze
psql -U myhibachi_user -d myhibachi -c "VACUUM ANALYZE;"

# Re-run performance tests
cd apps/backend
pytest tests/test_api_performance.py -v
```

---

#### Issue: Postman tests failing

**Solution:**

1. Verify server is running: http://localhost:8000/docs
2. Get fresh admin token:

```powershell
curl -X POST http://localhost:8000/api/auth/login `
  -H "Content-Type: application/json" `
  -d '{\"email\": \"admin@myhibachi.com\", \"password\": \"your_password\"}'
```

3. Update token in Postman environment
4. Re-run collection

---

#### Issue: Cache tests not working

**Solution:**

1. Clear browser cache: Ctrl+Shift+Del
2. Open DevTools â†’ Console
3. Run: `window.blogCache.clear()`
4. Reload page
5. Verify cache functionality

---

### Debug Mode

**Enable Verbose Output:**

```powershell
# Backend: Verbose pytest output
cd apps/backend
pytest tests/ -v -s --log-cli-level=DEBUG

# Frontend: Verbose Vitest output
cd apps/customer
npm test -- --reporter=verbose

# API: Enable debug logging
# Edit apps/backend/.env
LOG_LEVEL=DEBUG
```

---

## Summary

### Test Execution Matrix

| Test Type           | Command                                | Duration | Frequency      |
| ------------------- | -------------------------------------- | -------- | -------------- |
| Backend Unit        | `pytest tests/ -m unit`                | <5s      | Every commit   |
| Backend Integration | `pytest tests/ -m integration`         | <30s     | Every PR       |
| Frontend Unit       | `npm test`                             | <10s     | Every commit   |
| Performance         | `pytest tests/test_api_performance.py` | <1min    | Weekly         |
| Load Tests          | `pytest tests/test_api_load.py`        | <3min    | Before release |
| Manual Tests        | Interactive                            | <30min   | Before release |
| Postman Collection  | Newman CLI                             | <2min    | Daily          |

---

### Quick Reference

**Run Everything:**

```powershell
# Backend (from apps/backend)
pytest tests/ -v --cov=app --cov-report=html

# Frontend (from apps/customer)
npm test -- --coverage

# Postman (from project root)
newman run tests/postman/MyHibachi_API_Performance_Tests.postman_collection.json
```

**Smoke Test (30 seconds):**

```powershell
# Backend
cd apps/backend
pytest tests/ -v -m smoke

# Frontend
cd apps/customer
npm test -- --run
```

**Coverage Reports:**

```powershell
# Backend
cd apps/backend
pytest tests/ --cov=app --cov-report=html
start htmlcov/index.html

# Frontend
cd apps/customer
npm run test:coverage
start coverage/index.html
```

---

## Next Steps

### Immediate Actions

1. âœ… Install testing dependencies (5 min)
2. âœ… Run smoke tests to verify setup (30 sec)
3. âœ… Run full test suite (2 min)
4. âœ… Generate coverage reports (1 min)
5. âœ… Review and fix any failing tests

### Short Term (This Week)

1. â³ Set up CI/CD GitHub Actions workflow
2. â³ Add E2E tests with Playwright
3. â³ Increase frontend coverage to 85%
4. â³ Add accessibility tests (WCAG 2.1 AA)
5. â³ Set up pre-commit hooks

### Long Term (This Month)

1. â³ Implement visual regression testing
2. â³ Set up load testing with K6
3. â³ Add security testing with OWASP ZAP
4. â³ Create test result dashboards
5. â³ Establish test data management strategy

---

**Document Version:** 2.0  
**Last Updated:** October 25, 2025  
**Maintained By:** Development Team  
**Status:** âœ… Production Ready

---

## Related Documentation

- [AUTOMATED_API_TESTING_GUIDE.md](./AUTOMATED_API_TESTING_GUIDE.md) -
  Original API testing guide
- [COMPREHENSIVE_TESTING_STRATEGY.md](./COMPREHENSIVE_TESTING_STRATEGY.md) -
  Newsletter testing strategy
- [COMPLETE_TEST_SUITE_DOCUMENTATION.md](./COMPLETE_TEST_SUITE_DOCUMENTATION.md) -
  Detailed test suite docs
- [MANUAL_TESTING_GUIDE.md](./MANUAL_TESTING_GUIDE.md) - Manual
  testing procedures
- [DATABASE_SETUP_GUIDE.md](./DATABASE_SETUP_GUIDE.md) - Database
  setup for testing
- [LOCAL_DEVELOPMENT_SETUP.md](./LOCAL_DEVELOPMENT_SETUP.md) - Dev
  environment setup

---
